{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial follow the same steps of fastai course lecture 11 on translation http://course.fast.ai/lessons/lesson11.html\n",
    "\n",
    "see: https://github.com/fastai/fastai/blob/master/courses/dl2/translate.ipynb\n",
    "\n",
    "It showcasess the seq2seq, seq2seq with attention and transformer models of quicknlp and how\n",
    "they can be used without using the quicknlp modeldata objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first data is downloaded\n",
    "#!wget http://www.statmt.org/wmt10/training-giga-fren.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import pickle\n",
    "from fastai.text import Tokenizer, SortishSampler, SortSampler\n",
    "from fastai.core import partition_by_cores, A, to_gpu, V, to_np\n",
    "from fastai.dataset import Dataset, DataLoader, ModelData\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from quicknlp.data.learners import EncoderDecoderLearner\n",
    "from quicknlp.models import Seq2Seq, Seq2SeqAttention, Transformer\n",
    "from quicknlp.data.model_helpers import S2SModel\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('dataset/translate')\n",
    "TMP_PATH = PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)\n",
    "fname='giga-fren.release2.fixed'\n",
    "en_fname = PATH/f'{fname}.en'\n",
    "fr_fname = PATH/f'{fname}.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_fq = re.compile('^([^?.!]+\\?)')\n",
    "lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
    "         for eq, fq in zip(open(en_fname, encoding='utf-8'), open(fr_fname, encoding='utf-8')))\n",
    "qs = [(e.group(), f.group()) for e,f in lines if e and f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(qs, (PATH/'fr-en-qs.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = pickle.load((PATH/'fr-en-qs.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs[:5], len(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_qs,fr_qs = zip(*qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = Tokenizer.proc_all_mp(partition_by_cores(en_qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_tok = Tokenizer.proc_all_mp(partition_by_cores(fr_qs), 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok[0], fr_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile([len(o) for o in en_tok], 90), np.percentile([len(o) for o in fr_tok], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.array([len(o)<30 for o in en_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = np.array(en_tok)[keep]\n",
    "fr_tok = np.array(fr_tok)[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(en_tok, (PATH/'en_tok.pkl').open('wb'))\n",
    "pickle.dump(fr_tok, (PATH/'fr_tok.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = pickle.load((PATH/'en_tok.pkl').open('rb'))\n",
    "fr_tok = pickle.load((PATH/'fr_tok.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def toks2ids(tok,pre):\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common(40000)]\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk_')\n",
    "    stoi = defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([stoi[o] for o in p] + [2]) for p in tok])\n",
    "    np.save(TMP_PATH/f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = toks2ids(en_tok,'en')\n",
    "fr_ids,fr_itos,fr_stoi = toks2ids(fr_tok,'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ids(pre):\n",
    "    ids = np.load(TMP_PATH/f'{pre}_ids.npy')\n",
    "    itos = pickle.load(open(TMP_PATH/f'{pre}_itos.pkl', 'rb'))\n",
    "    stoi = defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = load_ids('en')\n",
    "fr_ids,fr_itos,fr_stoi = load_ids('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[fr_itos[o] for o in fr_ids[0]], len(en_itos), len(fr_itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the fastText library, you'll need to download [fasttext word vectors](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md) for your language (download the 'bin plus text' ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecs = ft.load_model(str((PATH/'wiki.en.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_vecs = ft.load_model(str((PATH/'wiki.fr.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vecs(lang, ft_vecs):\n",
    "    vecd = {w:ft_vecs.get_word_vector(w) for w in ft_vecs.get_words()}\n",
    "    pickle.dump(vecd, open(PATH/f'wiki.{lang}.pkl','wb'))\n",
    "    return vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = get_vecs('en', en_vecs)\n",
    "fr_vecd = get_vecs('fr', fr_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = pickle.load(open(PATH/'wiki.en.pkl','rb'))\n",
    "fr_vecd = pickle.load(open(PATH/'wiki.fr.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_en_vec = len(en_vecd[','])\n",
    "dim_fr_vec = len(fr_vecd[','])\n",
    "dim_en_vec,dim_fr_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0075652334, 0.29283327)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vecs = np.stack(list(en_vecd.values()))\n",
    "en_vecs.mean(),en_vecs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0014966384, 0.2718286)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_vecs = np.stack(list(fr_vecd.values()))\n",
    "fr_vecs.mean(),fr_vecs.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 33)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlen_90 = int(np.percentile([len(o) for o in en_ids], 99))\n",
    "frlen_90 = int(np.percentile([len(o) for o in fr_ids], 97))\n",
    "enlen_90,frlen_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids_tr = np.array([o[:enlen_90] for o in en_ids])\n",
    "fr_ids_tr = np.array([o[:frlen_90] for o in fr_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __getitem__(self, idx): return A(self.x[idx], [0] + self.y[idx], self.y[idx])\n",
    "    def __len__(self): return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45219, 5041)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(en_ids_tr))>0.1\n",
    "en_trn,fr_trn = en_ids_tr[trn_keep],fr_ids_tr[trn_keep]\n",
    "en_val,fr_val = en_ids_tr[~trn_keep],fr_ids_tr[~trn_keep]\n",
    "len(en_trn),len(en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = Seq2SeqDataset(fr_trn,en_trn)\n",
    "val_ds = Seq2SeqDataset(fr_val,en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_samp = SortishSampler(en_trn, key=lambda x: len(en_trn[x]), bs=bs)\n",
    "val_samp = SortSampler(en_val, key=lambda x: len(en_val[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2SDataLoader(DataLoader):\n",
    "    def get_batch(self, indices):\n",
    "        res = self.np_collate([self.dataset[i] for i in indices])\n",
    "        if self.transpose:   res[0], res[1] = res[0].T, res[1].T\n",
    "        if self.transpose_y: res[2] = res[2].T\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = S2SDataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = S2SDataLoader(val_ds, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(31, 12, 11), (21, 8, 7), (21, 9, 8), (33, 14, 13), (33, 22, 21)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x),len(y), len(t)) for x,y,t in its]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.cuda.LongTensor, torch.cuda.LongTensor, torch.cuda.LongTensor)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(its[0][0]), type(its[0][1]), type(its[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w]*3)\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24793 ['de', 'les', '-', 'la', 'le']\n",
      "17573 ['the', 'what', 'of', 'to', 'is']\n"
     ]
    }
   ],
   "source": [
    "input_embedding = create_emb(fr_vecd, fr_itos, dim_fr_vec)\n",
    "output_embedding = create_emb(en_vecd, en_itos, dim_en_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24793, 300])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_embedding' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7a88d11e60eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m seq2seqmodel = Seq2Seq(\n\u001b[0;32m----> 2\u001b[0;31m             \u001b[0mntoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m             \u001b[0memb_sz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mnhid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mnlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_embedding' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "seq2seqmodel = Seq2Seq(\n",
    "            ntoken=[input_embedding.weight.size(0), output_embedding.weight.size(0)],\n",
    "            emb_sz=[input_embedding.weight.size(1), output_embedding.weight.size(1)],\n",
    "            nhid=256,\n",
    "            nlayers=2,\n",
    "            pad_token=1,\n",
    "            eos_token=2,\n",
    "            max_tokens=34,\n",
    "            cell_type='gru',\n",
    "            dropout_e= [0.15, 0.],\n",
    "            dropout_i= 0.,\n",
    "            dropout_d = 0.35,\n",
    "            wdrop = 0.,\n",
    "            dropouth = [0.25, 0.1],\n",
    "            bidir=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the embedding matrices\n",
    "seq2seqmodel.encoder.embedding_layer.encoder_with_dropout.embed.weight = input_embedding.weight\n",
    "seq2seqmodel.decoder.embedding_layer.encoder_with_dropout.embed.weight = output_embedding.weight\n",
    "seq2seqmodel.decoder.projection_layer.layers[-1].weight = output_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(Adam, betas=(0.8, 0.99))\n",
    "model = S2SModel(to_gpu(seq2seqmodel))\n",
    "learn = EncoderDecoderLearner(md, model, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10), teacher_forcing=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "*x,y = next(iter(val_dl))\n",
    "learn.model.eval()\n",
    "probs = learn.model(*V(x),num_beams=1)[0]\n",
    "\n",
    "preds=to_np(probs[...,0])\n",
    "\n",
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[0][:,i] if o > 2]))\n",
    "    print(\"--->\")\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o > 2]))\n",
    "    print(\"====\")\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o > 2]))\n",
    "    print(\"******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_np(probs).shape, y.shape, preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher Forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seqmodel = Seq2Seq(\n",
    "            ntoken=[input_embedding.weight.size(0), output_embedding.weight.size(0)],\n",
    "            emb_sz=[input_embedding.weight.size(1), output_embedding.weight.size(1)],\n",
    "            nhid=256,\n",
    "            nlayers=2,\n",
    "            pad_token=1,\n",
    "            eos_token=2,\n",
    "            max_tokens=34,\n",
    "            cell_type='gru',\n",
    "            dropout_e =[0.15, 0.],\n",
    "            dropout_i = 0.,\n",
    "            wdrop = 0.,\n",
    "            dropouth = [0.25, 0.1],\n",
    "            bidir=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the embedding matrices\n",
    "seq2seqmodel.encoder.embedding_layer.encoder_with_dropout.embed.weight = input_embedding.weight\n",
    "seq2seqmodel.decoder.embedding_layer.encoder_with_dropout.embed.weight = output_embedding.weight\n",
    "seq2seqmodel.decoder.projection_layer.layers[-1].weight = output_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(Adam, betas=(0.8, 0.99))\n",
    "model = S2SModel(to_gpu(seq2seqmodel))\n",
    "learn = EncoderDecoderLearner(md, model, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10), teacher_forcing=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('teacherforcing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('teacherforcing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "*x,y = next(iter(val_dl))\n",
    "learn.model.eval()\n",
    "probs = learn.model(*V(x),num_beams=1)[0]\n",
    "\n",
    "preds=to_np(probs[...,0])\n",
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[0][:,i] if o > 2]))\n",
    "    print(\"--->\")\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o > 2]))\n",
    "    print(\"====\")\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o > 2]))\n",
    "    print(\"******\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seqmodel = Seq2Seq(\n",
    "            ntoken=[input_embedding.weight.size(0), output_embedding.weight.size(0)],\n",
    "            emb_sz=[input_embedding.weight.size(1), output_embedding.weight.size(1)],\n",
    "            nhid=256,\n",
    "            nlayers=2,\n",
    "            pad_token=1,\n",
    "            eos_token=2,\n",
    "            max_tokens=34,\n",
    "            cell_type='gru',\n",
    "            dropout_e =[0.15, 0.],\n",
    "            dropout_i = 0.,\n",
    "            wdrop = 0.,\n",
    "            dropouth = [0.25, 0.1],\n",
    "            bidir=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the embedding matrices\n",
    "seq2seqmodel.encoder.embedding_layer.encoder_with_dropout.embed.weight = input_embedding.weight\n",
    "seq2seqmodel.decoder.embedding_layer.encoder_with_dropout.embed.weight = output_embedding.weight\n",
    "seq2seqmodel.decoder.projection_layer.layers[-1].weight = output_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(Adam, betas=(0.8, 0.99))\n",
    "model = S2SModel(to_gpu(seq2seqmodel))\n",
    "learn = EncoderDecoderLearner(md, model, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10), teacher_forcing=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('bidirtf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('bidirtf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "*x,y = next(iter(val_dl))\n",
    "learn.model.eval()\n",
    "probs = learn.model(*V(x),num_beams=1)[0]\n",
    "\n",
    "preds=to_np(probs[...,0])\n",
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[0][:,i] if o > 2]))\n",
    "    print(\"--->\")\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o > 2]))\n",
    "    print(\"====\")\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o > 2]))\n",
    "    print(\"******\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seqmodel = Seq2SeqAttention(\n",
    "            ntoken=[input_embedding.weight.size(0), output_embedding.weight.size(0)],\n",
    "            emb_sz=[input_embedding.weight.size(1), output_embedding.weight.size(1)],\n",
    "            nhid=256,\n",
    "            nlayers=2,\n",
    "            pad_token=1,\n",
    "            eos_token=2,\n",
    "            max_tokens=34,\n",
    "            cell_type='gru',\n",
    "            dropout_e =[0.15, 0.],\n",
    "            dropout_i = [0.2, 0.1],\n",
    "            wdrop = 0.,\n",
    "            dropouth = [0.25, 0.1],\n",
    "            att_nhid=256,\n",
    "            bidir=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the embedding matrices\n",
    "seq2seqmodel.encoder.embedding_layer.encoder_with_dropout.embed.weight = input_embedding.weight\n",
    "seq2seqmodel.decoder.embedding_layer.encoder_with_dropout.embed.weight = output_embedding.weight\n",
    "seq2seqmodel.decoder.projection_layer.projection2.weight = output_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(Adam, betas=(0.8, 0.99))\n",
    "model = S2SModel(to_gpu(seq2seqmodel))\n",
    "learn = EncoderDecoderLearner(md, model, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 240/362 [00:22<00:11, 10.50it/s, loss=29.6]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   \n",
      "    0      3.172091   2.998817  \n",
      "    1      3.325651   2.861877  \n",
      "    2      3.199467   2.815038  \n",
      "    3      3.109225   2.788246  \n",
      "    4      3.048564   2.724706  \n",
      "    5      2.99165    2.699182  \n",
      "    6      2.899239   2.667038  \n",
      "    7      2.798418   2.640215  \n",
      "    8      2.766275   2.632312  \n",
      "    9      2.734976   2.619201  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.6192])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=10, use_clr=(20,10), teacher_forcing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('attention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('attention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quelles composantes des différents aspects de la performance devraient être mesurées , quelles données pertinentes recueillir et comment ?\n",
      "--->\n",
      "what components of the different of be be be be , and what data and be be ?\n",
      "====\n",
      "which components within various performance areas should be measured , whatkinds of data are appropriate to collect , and how should this be done ?\n",
      "******\n",
      "le premier ministre doit - il nommer un ministre d’ état à la santé mentale , à la maladie mentale et à la toxicomanie ?\n",
      "--->\n",
      "what is the minister minister the minister minister a a mental mental health , mental mental , and ? ?\n",
      "====\n",
      "what role can the federal government play to ensure that individuals with mental illness and addiction have access to the drug therapy they need ?\n",
      "******\n",
      "quelles sont les conséquences de la hausse des formes d’ emploi non conformes aux normes chez les travailleurs hautement qualifiés et chez ceux qui occupent des emplois plus marginaux ?\n",
      "--->\n",
      "what are the consequences of the of non - - - - - - workers and workers and workers to workers ? ?\n",
      "====\n",
      "what is the impact of growing forms of non - standard employment for highly skilled workers and for those employed in more marginal occupations ?\n",
      "******\n",
      "que se produit - il si le gestionnaire n’ est pas en mesure de donner à l’ employé nommé pour une période déterminée un préavis de cessation d’ emploi d’ un mois ou\n",
      "--->\n",
      "what if the manager is not not to to a a employee employee a a a a a a a a a a a a a a a ?\n",
      "====\n",
      "what happens if the manager is unable to or neglects to give a term employee the one - month notice of non - renewal ?\n",
      "******\n",
      "quelles personnes , communautés ou entités sont considérées comme potentiels i ) bénéficiaires de la protection et ii ) titulaires de droits ?\n",
      "--->\n",
      "who , communities or or are as as a of of of and and and and and ? ? ?\n",
      "====\n",
      "which persons , communities or entities are identified as potential ( i ) beneficiaries of protection and / or ( ii ) rights holders ?\n",
      "******\n",
      "quelles conditions particulières doivent être remplies pendant l’ examen préliminaire international en ce qui concerne les listages des séquences de nucléotides ou d’ acides aminés ou les tableaux y relatifs ?\n",
      "--->\n",
      "what special conditions must be to to the the international preliminary preliminary examination or or or or or or or or or or ?\n",
      "====\n",
      "what special requirements apply during the international preliminary examination to nucleotide and / or amino acid sequence listings and / or tables related thereto ?\n",
      "******\n",
      "pourquoi cette soudaine réticence à promouvoir l’ égalité des genres et à protéger les femmes de ce que , dans la plupart des cas , on peut qualifier de violations grossières des droits\n",
      "--->\n",
      "why would this that be to to to to of of of and and and and to to of of of of of of of ?\n",
      "====\n",
      "why this sudden reluctance to effectively promote gender equality and protect women from what are – in many cases – egregious human rights violations ?\n",
      "******\n",
      "pouvez - vous dire comment votre bagage culturel vous a aidée à aborder votre nouvelle vie au canada ( à vous adapter au mode de vie canadien ) ?\n",
      "--->\n",
      "what do you say you your your your your your new new to to to canada to to to to to to ? ?\n",
      "====\n",
      "what are some things from your cultural background that have helped you navigate canadian life ( helped you adjust to life in canada ) ?\n",
      "******\n",
      "selon vous , quels seront , dans les dix prochaines années , les cinq enjeux les plus urgents en matière d' environnement et d' avenir viable pour vous et votre région ?\n",
      "--->\n",
      "what do you see , the be the next next years years , the the and and and and and in in your ? ?\n",
      "====\n",
      "which do you think will be the five most pressing environmental and sustainability issues for you and your region in the next ten years ?\n",
      "******\n",
      "dans quelle mesure l’ expert est-il motivé et capable de partager ses connaissances , et dans quelle mesure son successeur est-il motivé et capable de recevoir ce savoir ?\n",
      "--->\n",
      "what is the the of the and and and and and and and and and and and and and and to ? ?\n",
      "====\n",
      "what is the expert ’s level of motivation and capability for sharing knowledge , and the successor ’s motivation and capability of acquiring it ?\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "*x,y = next(iter(val_dl))\n",
    "learn.model.eval()\n",
    "probs = learn.model(*V(x),num_beams=1)[0]\n",
    "\n",
    "preds=to_np(probs[...,0])\n",
    "\n",
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[0][:,i] if o > 2]))\n",
    "    print(\"--->\")\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o > 2]))\n",
    "    print(\"====\")\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o > 2]))\n",
    "    print(\"******\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seqmodel = Transformer(\n",
    "            ntoken=[input_embedding.weight.size(0), output_embedding.weight.size(0)],\n",
    "            emb_size=300,\n",
    "            nhid=512,\n",
    "            nlayers=6,\n",
    "            pad_token=1,\n",
    "            eos_token=2,\n",
    "            max_tokens=34,\n",
    "            dropout=0.1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the embedding matrices\n",
    "seq2seqmodel.encoder.embedding_layer.layers[0].embedding.weight = input_embedding.weight\n",
    "seq2seqmodel.decoder.embedding_layer.layers[0].embedding.weight = output_embedding.weight\n",
    "seq2seqmodel.decoder.projection_layer.layers[-1].weight = output_embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(Adam, betas=(0.8, 0.99))\n",
    "model = S2SModel(to_gpu(seq2seqmodel))\n",
    "learn = EncoderDecoderLearner(md, model, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "*x,y = next(iter(val_dl))\n",
    "learn.model.eval()\n",
    "probs = learn.model(*V(x),num_beams=1)[0]\n",
    "\n",
    "preds=to_np(probs[...,0])\n",
    "\n",
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[0][:,i] if o > 2]))\n",
    "    print(\"--->\")\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o > 2]))\n",
    "    print(\"====\")\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o > 2]))\n",
    "    print(\"******\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
